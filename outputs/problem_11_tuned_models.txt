PROBLEM 11: Improving the Model
=====================================

METRIC SELECTION:
- Chosen metric: f1
- Reason: Class imbalance ratio is 7.9:1
- F1 balances precision/recall for minority class

HYPERPARAMETER GRIDS SEARCHED:
- Logistic Regression: C=[0.01, 0.1, 1, 10], solver=['lbfgs', 'liblinear']
- KNN: n_neighbors=[3, 5, 7, 9, 11], weights=['uniform', 'distance']
- Decision Tree: max_depth=[3, 5, 7, 10, None], min_samples_split=[2, 5, 10]
- SVM: C=1.0, kernel='rbf' (limited due to training time)

TUNED RESULTS:

Logistic Regression:
  Best Params: {'C': 0.1, 'solver': 'liblinear'}
  CV F1: 0.3376
  Test Accuracy: 0.9008
  Test F1: 0.332

KNN:
  Best Params: {'n_neighbors': 5, 'weights': 'uniform'}
  CV F1: 0.3644
  Test Accuracy: 0.894
  Test F1: 0.3751

Decision Tree:
  Best Params: {'max_depth': 10, 'min_samples_split': 2}
  CV F1: 0.368
  Test Accuracy: 0.8989
  Test F1: 0.3986

SVM:
  Best Params: {'C': 1.0, 'kernel': 'rbf'}
  CV F1: 0.3367
  Test Accuracy: 0.9037
  Test F1: 0.3711

COMPARISON TABLE:
              Model  CV Score  Test Accuracy  Test F1  Tune Time (s)
Logistic Regression    0.3376         0.9008   0.3320           2.14
                KNN    0.3644         0.8940   0.3751           4.64
      Decision Tree    0.3680         0.8989   0.3986           3.86
                SVM    0.3367         0.9037   0.3711          18.88

DATA-DERIVED OBSERVATIONS:
- Metric used: f1 (due to 7.9:1 class imbalance)
- Best model: Decision Tree (Test F1=0.3986)

RECOMMENDATION: Decision Tree
